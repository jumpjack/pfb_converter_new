# Fixed bugs to support NASA files:#  PF_MAX_TEXTURES_19 = 4 (not 19)#  N_LOD is not a node of type "group"#  Added one "appearance" field to geoset reading (don't know why...)#  Added 1 position increment while reading geostate in case of statemode == STATE_ENTEXTURE#  aniso_degree wa read but not stored# 0.3.0: Added command line support# 0.2.0: Fixed to support both NASA and original files (LODS / no LODS)# 0.1.0: Implemented export of selected geosets by LOD level, but construction of faces is faulty:# to be found the algorithm for POLY/TRISTRIPS or what they are...# original support: PFGS_TRISTRIPS (constant = 5, table = position 1, PFB file = 1)# NASA files:  PFB file = 8: 8 in table is PFGS_FLAT_TRISTRIPS (constant = 7)import tracebackimport sys, structfrom pfb_constants import *import osimport urllib.requestimport urllib.errorimport argparseimport sslimport jsonproducts = ["EFF", "FFL", "RSL", "ILF", "MRL"]channels = ["0", "1", "2", "3", "4", "5", "6"]versions = ["1", "2", "3"]rovers =   ["nothing", "opportunity", "spirit"]availableTextureFiles = []html = "\n<html><body>\n"localNotFoundRaw = []onlineNotFoundRaw = []localNotFound = []onlineNotFound = []ccwRef = FalseENDIAN_FLAG = '>'PF_MAX_TEXTURES_19 = 4  # fixed to 4, not 19# making a logical assumption for the values of PF_OFF & PF_ON - doublecheck this, then move this stuff to pfb_constantsPF_OFF = 0PF_ON = 1OnOff_table = [ 2, PF_OFF, PF_ON ]def load_json(path):    with open(path, "r") as f:        return json.load(f)def find_texture_path(data, target):    target = target.upper()    def walk(node, path):        if isinstance(node, dict):            for key, value in node.items():                yield from walk(value, path + [key])        elif isinstance(node, list):            if target in node:                yield path        # se Ã¨ altro tipo, ignoro    # restituisce la prima occorrenza    for p in walk(data, []):        return p    return Nonedef readInt32(f):    data = f.read(4)    if data == "":        raise Exception("end of file")    return struct.unpack(ENDIAN_FLAG+'i', data)[0]def readUInt32(f):    data = f.read(4)    if data == "":        raise Exception("end of file")    return struct.unpack(ENDIAN_FLAG+'I', data)[0]def readUInt16(f):    data = f.read(2)    if data == "":        raise Exception("end of file")    return struct.unpack(ENDIAN_FLAG+'H', data)[0]def skipUInt8(f):    data = f.read(1)    if data == "":        raise Exception("end of file")    return datadef readFloat32(f):    data = f.read(4)    if data == "":        raise Exception("end of file")    return struct.unpack(ENDIAN_FLAG+'f', data)[0]def skipBytes(f, numbytes):    cur = f.tell()    f.seek(0, 2)    end = f.tell()    f.seek(cur)    if cur + numbytes > end:        raise Exception("end of file")    f.seek(numbytes, 1)def readInt32Array(f,num):    return [readInt32(f) for i in range(num)]def readUInt32Array(f,num):    return [readUInt32(f) for i in range(num)]def readUInt16Array(f,num):    return [readUInt16(f) for i in range(num)]def readFloat32Array(f,num):    return [readFloat32(f) for i in range(num)]def readPfVec4(f):    return readFloat32Array(f,4)def readPfVec3(f):    return readFloat32Array(f,3)def readPfVec2(f):    return readFloat32Array(f,2)def readPfVec4Array(f,num):    return [readPfVec4(f) for i in range(num)]def readPfVec3Array(f,num):    return [readPfVec3(f) for i in range(num)]def readPfVec2Array(f,num):    return [readPfVec2(f) for i in range(num)]class Tex0T:    def __init__(self,f):        self.format = readInt32Array(f,5)        self.filter = readUInt32Array(f,4)        self.wrap = readInt32Array(f,3)        self.bcolor = readPfVec4(f)        self.btype = readInt32(f)        self.ssp = readPfVec2Array(f,4)        self.ssc = readFloat32(f)        self.dsp = readPfVec2Array(f,4)        self.dsc = readFloat32(f)        self.tdetail = readInt32Array(f,2)        self.lmode = readInt32Array(f,3)        self.losource = readInt32Array(f,2)        self.lodest = readInt32Array(f,2)        self.lsize = readInt32Array(f,2)        self.image = readInt32(f)        self.comp = readInt32(f)        self.xsize = readInt32(f)        self.ysize = readInt32(f)        self.zsize = readInt32(f)        self.load_image = readInt32(f)        self.list_size = readInt32(f)        self.frame = readFloat32(f)        self.num_levels = readInt32(f)        self.udata = readInt32(f)        self.type = 0                  # does not read value now, it does later depending on PFB version        self.aniso_degree =  0         # does not read value now, it does later depending on PFB versionSIZEOF_CLIPTEX_T = 15*4SIZEOF_CLIPLEVEL_T = 7*4def readTextureData(version,f):    # Texture format:    #   int32: name length in bytes    #   length x int8: name    #   tex_0_t structure    #   version >=6:    #      int32: type    #   version >= 20:    #      int32: aniso_degree        try:      size = readInt32(f)      if size == -1:          pass      else:          name = f.read(size).decode('ascii')      if version >= PFBV_ANISOTROPY:     # version >= 20: read tex_t structure = tex_0_t + 1 x word32 (type) + 1 x word32 (aniso_degree)          # read tex_t (232 bytes)          t = Tex0T(f)          t.type = readInt32(f)          t.aniso_degree = readInt32(f)      elif version >= PFBV_CLIPTEXTURE:  #  version >= 6: read tex_1_t structure =  tex_0_t + 1 x word32 (type)           # read tex_1_t (228 bytes)          t = Tex0T(f)          t.type = readInt32(f)      else:                              # read tex_0_t structure          t = Tex0T(f)                if t.list_size > 0:          for i in range(t.list_size):              readInt32(f)      if t.type == TEXTYPE_TEXTURE:          if t.num_levels > 0:              for i in range(t.num_levels):                  readInt32(f)      else:          f.read(SIZEOF_CLIPTEX_T)          if t.num_levels > 0:              f.read(t.num_levels * SIZEOF_CLIPLEVEL_T)      t.filename = name      return t    except Exception as e:        traceback.print_exc()    def isGroupClassType(t):# remved N_LOD    return t in [N_GROUP, N_SCS, N_DCS, N_PARTITION, N_SCENE, N_SWITCH, N_SEQUENCE, N_LAYER, N_MORPH, N_ASD, N_FCS, N_DOUBLE_DCS, N_DOUBLE_FCS, N_DOUBLE_SCS ]class Node_data:    def __init__(self,node_type):        self.type = node_type        self.name = ""        self.children = []def int32_to_float32(x, little=True):    """    Reinterpreta un intero a 32 bit come float32.    Args:        x (int): valore intero da reinterpretare (con segno o senza)        little (bool): True per little-endian, False per big-endian    Returns:        float: valore float32 corrispondente    """    # Maschera per trattare x come unsigned a 32 bit    x_uint = x & 0xFFFFFFFF    # Scegli il formato struct in base all'endianness    fmt = '<I' if little else '>I'    packed = struct.pack(fmt, x_uint)    # Reinterpretare come float32 (stesso endian)    float_fmt = '<f' if little else '>f'    return struct.unpack(float_fmt, packed)[0]def readNode(version, f, counter):    try:        buf_size = readInt32(f)        buf = readInt32Array(f, buf_size) # Read chunk of words containing whole node data        node = Node_data(buf.pop(0)) # Store node type into node item "type"        if isGroupClassType(node.type):            # print(f"   Node {counter}: Group class")            count = buf.pop(0)            if node.type == N_GROUP:#                 # print(f"      Processing Group: storing {count} children:")                try:                    node.children = []                    for i in range(count):                        val = buf.pop(0)#                         # print(f"         {i}) Node n. {val}")                        node.children.append(val)                    #node.children = [buf.pop(0) for i in range(count)]                except Exception as e:                    traceback.print_exc()            else:                node_name = node_type_dict.get(node.type, f"UNKNOWN_NODE_{node.type}")                # print(f'      Unsupported group type {node.type} ({node_name})')        elif node.type == N_LOD:  # added, for NASA files#             # print(f"   Node {counter}:  LOD")            try:                rangesCount = buf.pop(0)#                 # print (f"      Extracting  {rangesCount + 1} ranges.")                # Ciclo 1: leggi (rangesCount + 1) valori float per 'ranges'                ranges = []                for i in range(rangesCount + 1):                    val = int32_to_float32(buf.pop(0), False)                    # print(f"        {val}")                    ranges.append(val)                node.ranges = ranges                # print (f"      Extracting  {rangesCount + 1} transitions.")                # Ciclo 2: leggi (rangesCount + 1) valori float per 'trans'                trans = []                for i in range(rangesCount + 1):                    val = int32_to_float32(buf.pop(0), False)                    # print(f"        {val}")                    trans.append(val)                node.transitions = trans                # Ciclo 3: leggi 3 valori float per le coordinate (sempre 3, non dipendono da rangesCount)                # print (f"      Extracting  3 coordinates for center.")                coords = []                for i in range(3):                    val = int32_to_float32(buf.pop(0), False)                    # print(f"        {val}")                    coords.append(val)                node.centerCoords = coords                # Leggi lodState e lodStateIndex                lodState = buf.pop(0)                lodStateIndex = buf.pop(0)                # Leggi il numero di figli                numChildren = buf.pop(0)                # print(f"      LOD has {numChildren} children")                # Ciclo 4: leggi gli indici dei figli (solo se numChildren != -1)                children = []                if numChildren != -1:                    for i in range(numChildren):                        childIndex = buf.pop(0)                        # print(f"        child node: n. {childIndex}")                        children.append(childIndex)                node.lodState = lodState                node.lodStateIndex = lodStateIndex                node.numChildren = numChildren                node.children = children            except Exception as e:                # print ("Non ha funzionato :-(")                traceback.print_exc()        elif node.type == N_GEODE:            count = buf.pop(0)            # print(f"   Node {counter}: Geode")            try:                # print(f"      Extracting {count} geosets.")                node.gsets = [buf.pop(0) for i in range(count)]            except Exception as e:                traceback.print_exc()        else:            node_name = node_type_dict.get(node.type, f"UNKNOWN_NODE_{node.type}")            # print(f'      No group, no geode, unsupported node type {node.type} ({node_name})')        node.isect_travmask = buf.pop(0)        node.app_travmask = buf.pop(0)        node.cull_travmask = buf.pop(0)        node.draw_travmask = buf.pop(0)        name_size = readInt32(f)        if name_size != -1:            node.name = f.read(name_size).decode('ascii')            # print(f"      Found name for this node: {node.name}")        return node    except Exception as e:        # print(f"   ======== NODE PARSING EXCEPTION ==========")        traceback.print_exc()# def readNode(version,f,counter):#     try:#         buf_size = readInt32(f)#         buf = readInt32Array(f,buf_size)#         node = Node_data(buf.pop(0))#         if isGroupClassType(node.type):#             # print(f"   Node {counter}: Group class")#             count = buf.pop(0)#             if node.type == N_GROUP:#                 # print(f"      Processing Group: storing {count} children.")#                 try:#                     node.children = [buf.pop(0) for i in range(count)]#                 except Exception as e:#                     traceback.print_exc()#             elif node.type == N_LOD: #added, for NASA files#                 # --- Struttura dati per memorizzare i geoset ---#                 geosets_list = []  # Lista globale per raccogliere tutti i geoset##                 # print(f"      Processing LOD: storing {count} ranges.")#                 try:#                     node.ranges = [buf.pop(0) for i in range(count)]#### #                 # print(f"      Processing LOD: storing {count} ranges.")# #                 try:# #                     node.ranges = [buf.pop(0) for i in range(count)]# #                     for r in node.ranges:# #                         # print(f"      Extracting range")####                 except Exception as e:#                     traceback.print_exc()#             else:#                 node_name = node_type_dict.get(node.type, f"UNKNOWN_NODE_{node.type}")#                 # print(f'      Unsupported group type {node.type} ({node_name})')#         elif node.type == N_GEODE:#             count = buf.pop(0)#             # print(f"   Node {counter}: Geode")#             try:#                 # print(f"      Extractring {count} geosets.")#                 node.gsets = [buf.pop(0) for i in range(count)]#             except Exception as e:#                 traceback.print_exc()#         else:#             node_name = node_type_dict.get(node.type, f"UNKNOWN_NODE_{node.type}")#             # print(f'      No group, no geode, unsupported node type {node.type} ({node_name})')##         node.isect_travmask = buf.pop(0)#         node.app_travmask = buf.pop(0)#         node.cull_travmask = buf.pop(0)#         node.draw_travmask = buf.pop(0)#         name_size = readInt32(f)#         if name_size != -1:#             node.name = f.read(name_size).decode('ascii')#             # print(f"      Found name for this node: {node.name}")#         return node#     except Exception as e:#         # print(f"   ======== NODE PARSING EXCEPTION ==========")#         traceback.print_exc()def build_node_tree(nodes):    try:      # insieme di tutti gli indici che compaiono come figli      referenced = set()      for n in nodes:          if hasattr(n, "children"):              for c in n.children:                  referenced.add(c)      # radici = nodi mai citati come figli      roots = [i for i in range(len(nodes)) if i not in referenced]      return roots    except Exception as e:        print(f"   ======== build_node_tree EXCEPTION ==========")        traceback.print_exc()def print_node_tree(nodes, index, indent=0, lod_counter=[0]):    """    Stampa l'albero dei nodi con numerazione progressiva per i LOD    lod_counter Ã¨ una lista (mutabile) per mantenere il conteggio tra chiamate ricorsive    """    try:        node = nodes[index]        node_type_name = node_type_dict.get(node.type, f"UNKNOWN_{node.type}")        name = f' "{node.name}"' if node.name else ""        # Gestione speciale per N_LOD        if node.type == N_LOD:            lod_counter[0] += 1  # Incrementa il contatore LOD            lod_marker = f" {lod_counter[0]}, {len(node.children)} ranges <<<<<<<<<<<<<<<"            # print("  " * indent + f"- Node {index}: {node_type_name}{name}{lod_marker}")        else:            lod_marker = ""            # print("  " * indent + f"- Node {index}: {node_type_name}{name}{lod_marker}")        # Se Ã¨ un GEODE, stampa i geoset        if node.type == N_GEODE:            if hasattr(node, "gsets"):                for g in node.gsets:                    pass                    #print("  " * (indent + 1) + f"* Geoset {g}")        # Discesa ricorsiva        for child_index in node.children:            print_node_tree(nodes, child_index, indent + 1, lod_counter)    except Exception as e:        print(f"   ========  print_node_tree EXCEPTION ==========")        traceback.print_exc()def build_LODS(nodes):    try:      lods = []      for i, n in enumerate(nodes):          if n.type == N_LOD:              geosets_per_range = []              for r_index, child in enumerate(n.children):                  geosets = collect_geosets_under_node(nodes, child)                  geosets_per_range.append(geosets)              lod_entry = {                  "node_index": i,                  "name": n.name,                  "ranges": list(n.ranges),                  "transitions": list(n.transitions),                  "children": list(n.children),                  "geosets": geosets_per_range              }              lods.append(lod_entry)      return lods    except Exception as e:        print(f"   ======== build_LODS EXCEPTION ==========")        traceback.print_exc()def select_geosets_for_lod(LODS, lod_level=None):    """    Ritorna il set dei geoset esportabili considerando TUTTI i nodi LOD.    Se un nodo non supporta il livello richiesto, usa il suo LOD peggiore.    """    try:      selected = set()      lodIndex = 0      for lod in LODS:          max_level = len(lod["geosets"]) - 1          # print (f"")          # print (f"====================")          # ---- costruzione info (geoset â†’ nodo) ----          pairs = []          for i, geos in enumerate(lod["geosets"]):              geode_node = lod["children"][i]              for g in geos:                  pairs.append(f"G{g}/L{lodIndex}/N{geode_node}")          pairs_str = ", ".join(pairs)          # print(f"LOD n.{lodIndex} (node {lod['node_index']}), "          # print(f"{len(pairs)} geosets ({pairs_str})")          # print (f"   Requested level:      {lod_level}")          # print (f"   Max level available:  {max_level}")          for i in range(max_level + 1):              r0 = lod["ranges"][i]              r1 = lod["ranges"][i + 1]              if (i == lod_level):                  pass                  # print(f"    distance {i}: {r1} <=====")              else:                  pass                  # print(f"    distance {i}: {r1}")          # scelta livello effettivo per questo nodo          if lod_level is None:              use_level = max_level          else:              use_level = min(lod_level, max_level)              if lod_level > max_level:                  pass                  # print(f"  SKIPPING (selected level = {lod_level})")              else:                # print(f"   --> using LOD level {use_level}")                for g in lod["geosets"][use_level]:                    selected.add(f"{g}/L{lodIndex}")          lodIndex = lodIndex + 1      # print(f"\nTotal geosets selected: {len(selected)}\n")      return selected    except Exception as e:        # print(f"   ======== select_geosets_for_lod EXCEPTION ==========")        traceback.print_exc()          def collect_geosets_under_node(nodes, node_index):    try:          node = nodes[node_index]      geosets = []      if node.type == N_GEODE and hasattr(node, "gsets"):          geosets.extend(node.gsets)      for c in node.children:          geosets.extend(collect_geosets_under_node(nodes, c))      return geosets    except Exception as e:        print(f"   ======== collect_geosets_under_node EXCEPTION ==========")        traceback.print_exc()class Mtl_data:    def __init__(self,version,f):        self.side = readInt32(f)        self.alpha = readFloat32(f)        self.shininess = readFloat32(f)        self.ambient = readPfVec3(f)        self.diffuse = readPfVec3(f)        self.specular = readPfVec3(f)        self.emission = readPfVec3(f)        self.cmode = readInt32Array(f,2)        self.udata = readInt32(f)class Gset_data:    def __init__(self, version, f, debug=False):        try:          self.debug = debug          pos = f.tell()  # Ottieni la posizione corrente nel file          primitiveType = readInt32(f)          if debug:              pass              if (args.verbose >=2):  print(f"        0x{pos:08x}: primitiveType = {primitiveType:08x}h ({primitiveType}, {gspt_table_strings[primitiveType]}, in node memorizzo {primitiveType})")          else:              pass              ## print(f"Looking for primitive type {primitiveType:08x}h in lookup table")          #self.ptype = gspt_table[primitiveType]          self.ptype = primitiveType #debug memorizzo valore grezzo letto da file          if not debug:              pass              ## print(f"  Result: {gspt_table[primitiveType]} = {gspt_table_strings[primitiveType]}")          pos = f.tell()          self.pcount = readInt32(f)          if (args.verbose >=2): print(f"        0x{pos:08x}: pcount = {self.pcount:08x}h ({self.pcount})")          pos = f.tell()          self.llist = readInt32(f)          if (args.verbose >=2): print(f"        0x{pos:08x}: llist = {self.llist:08x}h ({self.llist})")          pos = f.tell()          self.vlist = readInt32Array(f, 3)          pos = f.tell()          self.clist = readInt32Array(f, 3)          pos = f.tell()          self.nlist = readInt32Array(f, 3)          pos = f.tell()          self.tlist = readInt32Array(f, 3)          pos = f.tell()          self.draw_mode = readInt32Array(f, 3)          pos = f.tell()          self.gstate = readInt32Array(f, 2)          pos = f.tell()          self.line_width = readFloat32(f)          pos = f.tell()          self.point_size = readFloat32(f)          pos = f.tell()          self.draw_bin = readInt32(f)          pos = f.tell()          self.isect_mask = readUInt32(f)          pos = f.tell()          self.hlight = readInt32(f)          pos = f.tell()          self.bbox_mode = readInt32(f)          pos = f.tell()          self.bbox = readFloat32Array(f, 6)          pos = f.tell()          self.udata = readInt32(f)          if version >= PFBV_GSET_DO_DP:              pos = f.tell()              self.draw_order = readUInt32(f)              pos = f.tell()              self.decal_plane = readInt32(f)              pos = f.tell()              self.dplane_normal = readFloat32Array(f, 3)              pos = f.tell()              self.dplane_offset = readFloat32(f)          if version >= PFBV_GSET_BBOX_FLUX:              pos = f.tell()              self.bbox_flux = readInt32(f)          if version >= PFBV_MULTITEXTURE:              pos = f.tell()              self.multi_tlist = readInt32Array(f, 3 * (PF_MAX_TEXTURES_19 - 1))              dummy = readInt32(f) #debug ?!?!? "appearance"?        except Exception as e:            print(f"   ======== Gset_data EXCEPTION ==========")            traceback.print_exc()              def readGset(version, f, debug=False):    if debug:        # print("      Calling Gset_data in DEBUG mode.")        gset = Gset_data(version, f, debug)        # print("      Returned from Gset_data.")        return gset    else:        if (args.verbose >=1): print("Extracting geoset")        gset = Gset_data(version, f)        return gsetdef readMtl(version,f):    mtl = Mtl_data(version,f)    return mtlclass Gstate_data:    def __init__(self):        self.enlighting = False        self.entexture = False        self.frontmtl = -1        self.texture = -1    def read(self,version,f):#   pfb_fread(&buf_size, sizeof(int), 1, glb->ifp);  legge valore di buf_size# 	pfb_fread(buf, sizeof(int), buf_size, glb->ifp); legge buf_size x word32#     buf_pos = 0;#     end_of_states = buf_size - 1;#     while (buf_pos < end_of_states) { legge buf_size x stateModes# 	     i = buf[buf_pos++];#define STATE_TRANSPARENCY	 1#define STATE_ANTIALIAS		 2#define STATE_DECAL		 3#define STATE_ALPHAFUNC		 4#define STATE_ENLIGHTING	 5#define STATE_ENTEXTURE		 6#define STATE_ENFOG		 7#define STATE_CULLFACE		 8#define STATE_ENWIREFRAME	 9#define STATE_ENCOLORTABLE	10#define STATE_ENHIGHLIGHTING	11#define STATE_ENLPOINTSTATE	12#define STATE_ENTEXGEN		13#define STATE_ALPHAREF		14#define STATE_FRONTMTL		15#define STATE_BACKMTL		16#define STATE_TEXTURE		17#define STATE_TEXENV		18#define STATE_FOG		19#define STATE_LIGHTMODEL	20#define STATE_LIGHTS		21#define STATE_COLORTABLE	22#define STATE_HIGHLIGHT		23#define STATE_LPOINTSTATE	24#define STATE_TEXGEN		25#define STATE_ENTEXMAT		26#define STATE_TEXMAT		27#define STATE_ENTEXLOD		28#define STATE_TEXLOD		29#define STATE_VERTEX_PROGRAM	30#define STATE_FRAGMENT_PROGRAM	31#define STATE_ENVTXPROG		32#define STATE_ENFRAGPROG	33#define STATE_GPROGPARMS        34#define STATE_SHADPROG          35#define STATE_ENSHADPROG        36#define STATE_END		-1        try:          initialOffset = f.tell()          buf_size = readInt32(f)          if (args.verbose >=2): print(f"   ========== Reading Geostate from             0x{initialOffset:08x}; size: {buf_size} x words32.")  #NOTE: not all of the data in buf is actually Int32's - some of it can be 32-bit floats (for alpharef and for texture matrices); the original PFB code would use pointer casting to convert those parts to floats; may be able to do the same thing with Python's struct functions, but it could be messy          buf = readInt32Array(f,buf_size)          pos = 0          endpos = buf_size - 1          if (args.verbose >=2): print(f"        0x{(initialOffset +  4*pos):08X}: buffer length: {buf_size} state modes, {buf_size * 4} bytes remaining to read:")          while pos < endpos:              statemode = buf[pos]              pos += 1              # print(f"        0x{(initialOffset +  4*pos):08X}: {statemode:08X} ({statemode})")              if statemode == STATE_ENLIGHTING: # 5                  index = buf[pos]                  self.enlighting = (OnOff_table[index] == PF_ON)                  # print(f"          ENLIGHTING = {self.enlighting} , +4 ")                  pos += 1              elif statemode == STATE_ENTEXTURE: # 6                  self.entexture = (OnOff_table[buf[pos]] == PF_ON)                  # print(f"          ENTEXTURE  = {self.entexture} , +4 ")                  pos += 1                  if version >= PFBV_MULTITEXTURE: # 19                      # would need to replace add a multitex alternative to "entexture"                      # print(f"            version > 26")                      pos += PF_MAX_TEXTURES_19-1  # 4-1                      # print(f"            +4*{PF_MAX_TEXTURES_19-1} ")              elif statemode == STATE_FRONTMTL: # 15                  #NOTE: this is an index into the list 'data.mtl'; in original PFB code it assumed the mtl info came first, so it was looked up at this point to set the material number with pfGStateAttr                  self.frontmtl = buf[pos]                  # print(f"          FRONTMTL   = {self.frontmtl} , +4 ")                  pos += 1              elif statemode == STATE_TEXTURE:                  #NOTE: this is an index into the list 'data.tex'                  self.texture = buf[pos]                  # print(f"          TEXTURE    = {self.texture} , +4 ")                  pos += 1              elif statemode == STATE_TRANSPARENCY:                  #NOTE: this is an index into the list 'data.tex'                  self.trasparency = buf[pos]                  pos += 1                  # print(f"          STATE_TRANSPARENCY   = {self.trasparency} , +4 ")              elif statemode == STATE_END:                  pos = endpos                  # print(f"          End of geostate.")              else:                  print(f'      >>>> WARNING: stateMode "{statemode}" unsupported ; this geostate may be messed up as a result')        except Exception as e:            print(f"**** Error reading GSTATE : '{e}'")            traceback.print_exc()def readGstate(version,f):    gstate = Gstate_data()    gstate.read(version,f)    return gstatedef readLlist(version,f):    buf = readInt32Array(f,3)    size = buf[0]    llist = readInt32Array(f,size)    return llistdef readVlist(version,f):    buf = readInt32Array(f,3)    size = buf[0]    vlist = readPfVec3Array(f,size)    return vlistdef readClist(version,f):    buf = readInt32Array(f,3)    size = buf[0]    clist = readPfVec4Array(f,size)    return clistdef readNlist(version,f):    buf = readInt32Array(f,3)    size = buf[0]    nlist = readPfVec3Array(f,size)    return nlistdef readTlist(version,f):    buf = readInt32Array(f,3)    size = buf[0]    tlist = readPfVec2Array(f,size)    return tlistdef readIlist(version,f):    buf = readInt32Array(f,3)    size = buf[0]    ilist = readUInt16Array(f,size)    return ilistclass modelData:    def __init__(self):        self.node = []        self.mtl = []        self.gset = []        self.gstate = []        self.llist = []        self.vlist = []        self.clist = []        self.nlist = []        self.tlist = []        self.ilist = []        self.tex = []def print_not_found_textures():    """Stampa le liste delle texture non trovate localmente e online"""        if localNotFound:        print("\n" + "="*60)        print("TEXTURE JPG NON TROVATE LOCALMENTE:")        print("="*60)        for i, texture in enumerate(localNotFound, 1):            print(f"{i:3d}. {texture.filename}")        print(f"Totale texture JPG non trovate localmente: {len(localNotFound)}")    else:        print("âœ“ Tutte le texture JPG sono state trovate localmente")        if onlineNotFound:        print("\n" + "="*60)        print("TEXTURE JPG NON TROVATE ONLINE:")        print("="*60)        for i, texture in enumerate(onlineNotFound, 1):            print(f"{i:3d}. {texture.filename}")        print(f"Totale texture JPG non trovate online: {len(onlineNotFound)}")    else:        print("âœ“ Tutte le texture JPG sono state trovate online")            if localNotFoundRaw:        print("\n" + "="*60)        print("TEXTURE IMG NON TROVATE LOCALMENTE:")        print("="*60)        for i, texture in enumerate(localNotFoundRaw, 1):            print(f"{i:3d}. {texture.filename}")        print(f"Totale texture IMG non trovate localmente: {len(localNotFoundRaw)}")    else:        print("âœ“ Tutte le texture IMG sono state trovate localmente")        if onlineNotFoundRaw:        print("\n" + "="*60)        print("TEXTURE IMG NON TROVATE ONLINE:")        print("="*60)        for i, texture in enumerate(onlineNotFoundRaw, 1):            print(f"{i:3d}. {texture.filename}")        print(f"Totale texture IMG non trovate online: {len(onlineNotFoundRaw)}")    else:        print("âœ“ Tutte le texture IMG sono state trovate online")                # Stampa riepilogo generale    print("\n" + "="*60)    print("RIEPILOGO:")    print("="*60)    print(f"Texture non trovate localmente: {len(localNotFound)}")    print(f"Texture non trovate online: {len(onlineNotFound)}")    print(f"Texture totali non disponibili: {len(set(localNotFound + onlineNotFound))}")        def  NASAtextureSearch(original_texture_filename, destinationFolder) :    MAXATTEMPTS = 10    attempts = 0    def try_texture(filename, url, online, local_path, rawIMG):        local_path = os.path.join(destinationFolder, args.textures_folder, filename)                if (rawIMG):          url = url.replace(args.texture_destination_extension,"img").replace("browse","data")          filename = filename.lower().replace(args.texture_destination_extension,"img")          local_path = local_path.replace(args.texture_destination_extension,"img")        else:          pass        tried_urls.append(url)        if (args.verbose >=1):     print(f"[NASAtextureSearch] [try_texture] Searching locally in {local_path} : {filename}, {rawIMG}")        if os.path.exists(local_path):            if (args.verbose >=1):                 print(f"[NASAtextureSearch] [try_texture]    [FOUND âœ…]")            return True        if (args.verbose >=1):             print(f"[NASAtextureSearch] [try_texture]    [not FOUND! âŒ] ")        if not online:            # Salva il nome della texture non trovata localmente            if (rawIMG):                localNotFoundRaw.append(texture)            else:                                localNotFound.append(texture)                            return False        try:            if (args.verbose >=1):                 print(f"[NASAtextureSearch] [try_texture] [Searching online ðŸŒ] {url}")            ssl._create_default_https_context = ssl._create_unverified_context            urllib.request.urlretrieve(url, local_path)            if (args.verbose >=1):                 print(f"[NASAtextureSearch] [try_texture]    [FOUND âœ…]")            return True        except urllib.error.HTTPError:            try:                url = url.replace("ffl","mrd")                if (args.verbose >=1):                     print(f"[NASAtextureSearch] [try_texture] [Searching online alternative ILFðŸŒ] {url}")                ssl._create_default_https_context = ssl._create_unverified_context                urllib.request.urlretrieve(url, local_path.replace("mrd","ffl"))                if (args.verbose >=1):                     print(f"[NASAtextureSearch] [try_texture]    [FOUND âœ…]")                return True            except urllib.error.HTTPError:                if (args.verbose >=1):                     print(f"[NASAtextureSearch] [try_texture]    [NOT FOUND! âŒ]")                # Salva il nome della texture non trovata online                if (rawIMG):                    onlineNotFoundRaw.append(texture)                else:                    onlineNotFound.append(texture)                            return False#         except Exception as e:#             if (args.verbose >=1): #                 print(f"[NASAtextureSearch] [try_texture]    [ERROR! âŒ] {str(e)}")#             if (rawIMG):#                 onlineNotFoundRaw.append(texture)#             else:#                 onlineNotFound.append(texture)#             return False    # PFB filename format:    # 2mesh_1352_f_131_ffl_651_v1    #   2 = rover number    #   mesh = constant    #     _ = separator    #   1352 = sol number    #     _ = separator    #   f = front hazard cam - string of f,r,n,p (front hazcam, rear hazcam, navcam, pancam)    #     _ = separator    #   131 = site    #     _ = separator    #   ffl = product    #     _ = separator    #   651 = rover location w.r.t site n. 131    #     _ = separator    #   v = constant    #   1 = version of file    #    # Resulting folder:    # JPG textures: https://planetarydata.jpl.nasa.gov/img/data/mer/spirit/mer2ho_0xxx/browse/sol1352/rdr/    # RAW textures: https://planetarydata.jpl.nasa.gov/img/data/mer/spirit/mer2ho_0xxx/data/sol1352/rdr/    # original_texture_filename: 2P292472658XYLB188P2361L0M1    #  2 = rover 2    #  P = pancam    #  292472658 = timestamp    #  XYL = product    #  B188 = site (B1) + relative location (88) of rover; warning: algorithm uses capital letters!    #  P2361 = sequence    #  l = constant    #  0 = camera channel    #  m = constan    #  1 = version of file    roverNumber = original_texture_filename[0].lower()    cameraLetter = original_texture_filename[1].lower()    if cameraLetter in ("r", "f"):        cameraLetter = "h"    roverNumber = original_texture_filename[0].lower()    cameraLetter = original_texture_filename[1].lower()    if cameraLetter in ("r", "f"):        cameraLetter = "h"                  # print(f"\nOriginal name: sol, rover, rover, camera= {solNumber},{roverNumber},{rovers[int(roverNumber)]},{cameraLetter}\n")    found = False    foundIMG = False    tried_urls = []    search_passes = [False, True]   # False = solo locale, True = locale + online        product_original = original_texture_filename[11:14].lower()    # Estrai le parti del nome file    prefix = original_texture_filename[0:11] # "2P292472658"    suffix = original_texture_filename[14:23] # "B188P2361"    original_l = original_texture_filename[23:24] # "L"    original_channel = original_texture_filename[24:25] # "2"    original_m = original_texture_filename[25:26] # "M"    original_version = original_texture_filename[26:27] # "1"    baseName = prefix + productAcronym + suffix # productAcronym Assigned at beginning    version = "1"    filename = (baseName.lower() + original_l + original_channel + original_m + version + ".img.jpg").lower() # debug - destination extension command line param    if (args.verbose >=0):  print(f"[NASAtextureSearch] Original texture:   {original_texture_filename}")    if (args.verbose >= 0): print(f"[NASAtextureSearch] JPG FFL product:    {filename}")        filesAvailabilityIMG = load_json("./IMGfiles.json")    imageId = filename.lower().replace('.img.jpg',"")                 #debug extension    ok = find_texture_path(        filesAvailabilityIMG,        imageId    )    solNumber = 0    print(f"Risultato ricerca sol per {imageId}: {ok}")    if (ok  == None):        solNumber = solNumberPFB        #print("Using sol number from pfb file")    else:                solNumber = ok[1].replace("sol","")        #print("Using sol number from db")            baseUrl = ("https://planetarydata.jpl.nasa.gov/img/data/mer/"                    + rovers[int(roverNumber)] + "/mer"                    + roverNumber + cameraLetter                    + "o_0xxx/browse/sol" + solNumber                    + "/rdr/")    url = baseUrl  + filename    tried_urls.append(url)    local_path = os.path.join(args.textures_folder, filename)            for online in search_passes:        try:          result = try_texture(filename, url, online,local_path, False)          if result:              availableTextureFiles.append(filename)              found = True                        result = try_texture(filename, url, online,local_path, True)          if result:              foundIMG = True          #html += "</body></html>\n"          if not found:              print("\n[NASAtextureSearch] [FAIL âŒ] Nessuna texture valida trovata\n\n")          else:              return filename.lower()        except Exception as e:          print(f"**** Errore in 'for online in search_passes' '{e}'")          traceback.print_exc()def print_tristrip_triangle(firstindex_v, firstindex_n, normal_mode, texc_mode, ccw, is_flat=False):    """    firstindex_v: Indice globale nell'array vertici (OBJ 0-based, poi aggiungiamo +1)    firstindex_n: Indice globale nell'array normali (OBJ 0-based, poi aggiungiamo +1)    is_flat: Se True, applica la logica Flat Shading (tutti i vertici usano la stessa normale)    """    # 1. Calcola gli indici dei Vertici (V) e Texture (VT)    # Assumiamo che le coordinate texture siano sempre 1:1 con i vertici    # OBJ Ã¨ 1-based, quindi aggiungiamo +1    v1, v2, v3 = firstindex_v + 1, firstindex_v + 2, firstindex_v + 3    vt1, vt2, vt3 = v1, v2, v3    # 2. Calcola gli indici delle Normali (VN)    if is_flat:        # In FLAT_TRISTRIPS, l'ultimo vertice definisce la normale per tutto il triangolo.        # L'indice 'firstindex_n' passato deve puntare alla normale di questo triangolo.        # Assegniamo la STESSA normale a tutti e tre i vertici della faccia.        vn_face = firstindex_n + 1        vn1 = vn2 = vn3 = vn_face    else:        # In TRISTRIPS standard (Smooth), ogni vertice ha la sua normale corrispondente.        vn1, vn2, vn3 = firstindex_n + 1, firstindex_n + 2, firstindex_n + 3    # 3. Gestione Winding (Counter-Clockwise)    # Se ccw Ã¨ False, invertiamo l'ordine degli ultimi due vertici per invertire la faccia    if not ccw:        # Scambiamo 2 e 3 (nota: gli indici array 0,1,2 corrispondono a v1,v2,v3)        v1, v2, v3 = v1, v3, v2        vt1, vt2, vt3 = vt1, vt3, vt2        vn1, vn2, vn3 = vn1, vn3, vn2    # 4. Scrittura nel file OBJ    # Combinazioni possibili di formati f v, f v//vn, f v/vt, f v/vt/vn    if texc_mode == PFGS_OFF and normal_mode == PFGS_OFF:        # Solo vertici: f v1 v2 v3        obj_file.write(f'f {v1} {v2} {v3}\n')    elif texc_mode == PFGS_OFF:        # Vertici + Normali: f v1//vn1 v2//vn2 v3//vn3        obj_file.write(f'f {v1}//{vn1} {v2}//{vn2} {v3}//{vn3}\n')    elif normal_mode == PFGS_OFF:        # Vertici + Texture: f v1/vt1 v2/vt2 v3/vt3        obj_file.write(f'f {v1}/{vt1} {v2}/{vt2} {v3}/{vt3}\n')    else:        # Completo: f v1/vt1/vn1 v2/vt2/vn2 v3/vt3/vn3        obj_file.write(f'f {v1}/{vt1}/{vn1} {v2}/{vt2}/{vn2} {v3}/{vt3}/{vn3}\n')############### Command line arguments management ############parser = argparse.ArgumentParser(description='PFB 3d converter')parser.add_argument('-t','--texture',                   default='NASA',                   choices=['NASA', 'other'],  # Valori validi                   help='Options: NASA, other . Specify if texture are standard or for NASA rovers')parser.add_argument('-i','--input',                   help='Input PFB file')parser.add_argument('-o','--output',                   help='Output OBJ file (optional; if not specified, input file will be used as base for the name). \n Default: "input.OBJ"')defaultOutputFolder = 'mymodels\\'parser.add_argument('-of','--output-folder',                   default = defaultOutputFolder,                   help=f'Folder for output files (.obj+.mtl) and textures folder. Must be already present. \nDefault: "{defaultOutputFolder}"')defaultTexturesFolder = 'textures\\'parser.add_argument('-tf','--textures-folder',                   default=defaultTexturesFolder,                   help= f'Folder to store downloaded textures, also referenced in MTL file. \nDefault: "{defaultTexturesFolder}"')defaultBaseFolder = '.\\'parser.add_argument('-bf','--base-folder',                   default=defaultBaseFolder,                   help= f'Root folder for output folder\nDefault: "{defaultBaseFolder}"')defaultLOD = 6parser.add_argument('-l','--LOD',                   default = defaultLOD,                   type = int,                   help= f'Level Of Detail (LOD); 0 = higher definition, 6 = minimum definition. Default: "{defaultLOD}"')defaultTSE = "rgb"parser.add_argument('-tse','--texture-source-extension',                   default = defaultTSE,                   help=f'Original extension of texture, to be changed into argument of --texture-destination-extension. \nDefault: "{defaultTSE}"')defaultTDE = "img.jpg"parser.add_argument('-tde','--texture-destination-extension',                   default = defaultTDE,                   help=f'Final extension of texture, from original specified in  --texture-source-extension. \nDefault: "{defaultTDE}"')defaultOnlyTextures = Falseparser.add_argument('-ot','--only-textures',                   default = defaultOnlyTextures,                   help=f'Parses PFB file to extract only terxtures names. \nDefault: "{defaultOnlyTextures}"')defaultReference = "x_zy"parser.add_argument('-r','--reference',                   default = defaultReference,                   help=f'Reference system: x_zy, xzy, xyz \nDefault: "{defaultReference}"')parser.add_argument('-v','--verbose',                   default = 0,                   type = int,                   help='Amount of debug messages shown')args = parser.parse_args()args.only_textures = str(args.only_textures)print(f"Input: {args.input}")print(f"Output: {args.output}")print(f"Base folder: {args.base_folder}")print(f"Output folder: {args.output_folder}")print(f"Textures folder: {args.textures_folder}")print(f"Only textures: {args.only_textures}")print(f"LOD: {args.LOD}")print(f"Textures source extension: {args.texture_source_extension}")print(f"Textures destination extension: {args.texture_destination_extension}")print(f"Verbose level: {args.verbose}")print(f"")# 2mesh_1352_f_131_ffl_651_v1# 1mesh_7_f_2_ffl_15_v3PFBfilename = args.inputparts = PFBfilename.split("_", 6)if len(parts) >= 3:    solNumberPFB = parts[1].zfill(4)    camerasLetters = parts[2]    siteNumber = parts[3].zfill(4)    productAcronym = parts[4]    roverDrive = parts[5].zfill(4)    PFBfileVersion = parts[6]else:    raise ValueError(f"Formato filename non valido: {PFBfilename}")################## Input file parsing #################f = open(args.input,'rb')magicnum = readUInt32(f)if (args.verbose >=2):  print('#magic number = ' + hex(magicnum))if magicnum == PFB_MAGIC_NUMBER_LE:    ENDIAN_FLAG = '<'version = readUInt32(f)if (args.verbose >=2):  print(f'#pfb version {version}')dummy = readInt32(f)byteoffset = readInt32(f)f.seek(byteoffset,0)data = modelData()while True:    try:        start_offset = f.tell()        listtype = readInt32(f)        numobjects = readInt32(f)        numbytes = readInt32(f)        end_offset = start_offset +  numbytes  +12 -1        # print(f'')        # print(f'##### Found list #####')        # print(f"##### {l_name[listtype]}" )        # print(f"Header:")        # print(f"      0x{start_offset:08X}:  0x{listtype:08X}   ({listtype}): listtype = {l_name[listtype]}")        # print(f"      0x{start_offset+1*4:08X}:  0x{numobjects:08X}   ({numobjects}):   {numobjects} objects")        # print(f"      0x{start_offset+2*4:08X}:  0x{numbytes:08X}   ({numbytes}): total length: {numbytes} bytes")        # print(f"Body: 0x{start_offset+3*4:08X}-0x{end_offset:08X}")        if listtype == L_TEX:            if (args.verbose >=1) : print(f"  L_TEX ({l_name[listtype]}),  {numobjects} objects, reading {numbytes} bytes")            for i in range(numobjects):                try:                    texture = readTextureData(version,f)                    # PFB:     2mesh_1352_f_131_ffl_651_v1                    # Texture: 2p296819864xylb1dqp2289l2m1.rgb                    name = texture.filename.lower()                    filesAvailabilityIMG = load_json("./IMGfiles.json")                    imageId = name.lower().replace('.rgb',"")                                    ok = find_texture_path(                        filesAvailabilityIMG,                        imageId                    )                    solNumber = 0                    if (ok  == None):                        solNumber = solNumberPFB                        #print("Using sol number from pfb file")                    else:                                solNumber = ok[1].replace("sol","")                        #print("Using sol number from db")                    roverNumber = name[0]                    cameraLetter = name[1].lower()                    if cameraLetter in ("r", "f"):                        cameraLetter = "h"                    baseUrl = ("https://planetarydata.jpl.nasa.gov/img/data/mer/"                                    + rovers[int(roverNumber)] + "/mer"                                    + roverNumber + cameraLetter                                    + "o_0xxx/browse/sol" + solNumber                                    + "/rdr/")                    if (args.verbose >=1): print(f"    {str(i).zfill(3)}: {texture.filename.lower()}")                    data.tex.append(texture)                except Exception as e:                  print(f"**** Error while extracting textures: '{e}'")                  traceback.print_exc()            # END FOR            if (args.only_textures.lower() == "true"):                print("    Only texture requested: PFB parsing stopped by user request, showing only textures.\n")                break;            else:                pass                # go on with processing        elif listtype == L_NODE:            if (args.verbose >=1) : print(f"  L_NODE ({l_name[listtype]}),  {numobjects} objects, reading {numbytes} bytes")            if (args.only_textures.lower() == "false"):              for i in range(numobjects):                  data.node.append(readNode(version,f,i))            else:              try:                print(f"    Only texture requested: skipping {l_name[listtype]}  ({numbytes} bytes)")                skipBytes(f, numbytes)              except Exception as e:                print(f"**** Error while skipping LIST: '{e}'")                traceback.print_exc()        elif listtype == L_MTL:            if (args.verbose >=1) : print(f"  L_MTL ({l_name[listtype]}),  {numobjects} objects, reading {numbytes} bytes")            if (args.only_textures.lower() == "false"):              for i in range(numobjects):                  data.mtl.append(readMtl(version,f))            else:              try:                print(f"    Only texture requested: skipping {l_name[listtype]}  ({numbytes} bytes)")                skipBytes(f, numbytes)                              except Exception as e:                print(f"**** Error while skipping LIST: '{e}'")                traceback.print_exc()        elif listtype == L_GSET:            if (args.verbose >=1) : print(f"  L_GSET ({l_name[listtype]}),  {numobjects} objects, reading {numbytes} bytes")            if (args.only_textures.lower() == "false"):              for i in range(numobjects): #debug                  # print(f"   ========== Reading gset n. {i}")                  try:                      # Chiamata con parametro "debug" - usa un valore booleano invece della stringa                      # Per attivare la modalitÃƒÂ  debug, chiama readGset(version, f, True)                      data.gset.append(readGset(version, f, True))  # Cambia False in True per debug                      # print(f"   Done n. {i}")                  except Exception as e:                      ## print(f"**** Error reading gset n. {i}: '{e}'")                      traceback.print_exc()            else:              try:                print(f"    Only texture requested: skipping {l_name[listtype]}  ({numbytes} bytes)")                skipBytes(f, numbytes)                              except Exception as e:                print(f"**** Error while skipping LIST: '{e}'")                traceback.print_exc()        elif listtype == L_GSTATE:            if (args.verbose >=1) : print(f"  L_GSTATE ({l_name[listtype]}),  {numobjects} objects, reading {numbytes} bytes")            if (args.only_textures.lower() == "false"):              for i in range(numobjects):                  data.gstate.append(readGstate(version,f))            else:              try:                print(f"    Only texture requested: skipping {l_name[listtype]}  ({numbytes} bytes)")                skipBytes(f, numbytes)                              except Exception as e:                print(f"**** Error while skipping LIST: '{e}'")                traceback.print_exc()        elif listtype == L_LLIST:            if (args.verbose >=1) : print(f"  L_LLIST ({l_name[listtype]}),  {numobjects} objects, reading {numbytes} bytes")            if (args.only_textures.lower() == "false"):              for i in range(numobjects):                  data.llist.append(readLlist(version,f))            else:              try:                print(f"    Only texture requested: skipping {l_name[listtype]}  ({numbytes} bytes)")                skipBytes(f, numbytes)                              except Exception as e:                print(f"**** Error while skipping LIST: '{e}'")                traceback.print_exc()        elif listtype == L_VLIST:            if (args.verbose >=1) : print(f"  L_VLIST ({l_name[listtype]}),  {numobjects} objects, reading {numbytes} bytes")            if (args.only_textures.lower() == "false"):              for i in range(numobjects):                  rawList = readVlist(version,f)                  # MER rovers reference system (https://planetarydata.jpl.nasa.gov/img/data/mer2-m-pancam-5-solar-ops-v1.0/mer2po_0xxx/document/mer_pppcs_excerpts.pdf) :                  #  +X = forward                  #  +Y = right                  #  +Z = down                  #                  #                                  | +Y                  #                                  |                  #                                  |                  #              ________ +X         |__________  +X                  #           /|                    /                  #         /  |                  /                  #       /    |                /  +Z                  #     /      | +Z -> Y-                  #   +Y -> +Z                  if (args.reference == "x_zy"):                  # Convert to screen coordinates: +Z = out of screen, i.e. up:                    processedList = [[v[0], -v[2], v[1]] for v in rawList]                    ccwRef = True                  elif (args.reference == "xzy"):                    processedList = [[v[0], v[2], v[1]] for v in rawList]                  elif (args.reference == "xyz"):                    processedList = [[v[0], v[1], v[2]] for v in rawList]                    ccwRef = True                  elif (args.reference == "xy_z"):                    processedList = [[v[0], v[1], -v[2]] for v in rawList]                    ccwRef = FaTruelse                  elif (args.reference == "x_y_z"):                    processedList = [[v[0], -v[1], -v[2]] for v in rawList]                    ccwRef = True                  elif (args.reference == "x_yz"):                    processedList = [[v[0], -v[1], v[2]] for v in rawList]                    ccwRef = True                  else:                  # Convert to screen coordinates: +Z = out of screen, i.e. up:                    processedList = [[v[0], -v[1], -v[2]] for v in rawList]                    ccwRef = True                  data.vlist.append(processedList)            else:              try:                print(f"    Only texture requested: skipping {l_name[listtype]}  ({numbytes} bytes)")                skipBytes(f, numbytes)                              except Exception as e:                print(f"**** Error while skipping LIST: '{e}'")                traceback.print_exc()        elif listtype == L_CLIST:            if (args.verbose >=1) : print(f"  L_CLIST ({l_name[listtype]}),  {numobjects} objects, reading {numbytes} bytes")            if (args.only_textures.lower() == "false"):              for i in range(numobjects):                  data.clist.append(readClist(version,f))            else:              try:                print(f"    Only texture requested: skipping {l_name[listtype]}  ({numbytes} bytes)")                skipBytes(f, numbytes)                              except Exception as e:                print(f"**** Error while skipping LIST: '{e}'")                traceback.print_exc()        elif listtype == L_NLIST:            if (args.verbose >=1) : print(f"  L_NLIST ({l_name[listtype]}),  {numobjects} objects, reading {numbytes} bytes")            if (args.only_textures.lower() == "false"):              for i in range(numobjects):                  data.nlist.append(readNlist(version,f))#                    rawList = readNlist(version,f)#                    # Assegna a processedList le triplette trasformate: [x, -z, y]#                    # n[0] Ã¨ x, n[1] Ã¨ y, n[2] Ã¨ z#                    processedList = [[n[0], n[1], n[2]] for n in rawList]#                    data.nlist.append(processedList)            else:              try:                print(f"    Only texture requested: skipping {l_name[listtype]}  ({numbytes} bytes)")                skipBytes(f, numbytes)                              except Exception as e:                print(f"**** Error while skipping LIST: '{e}'")                traceback.print_exc()        elif listtype == L_TLIST:            if (args.verbose >=1) : print(f"  L_TLIST ({l_name[listtype]}),  {numobjects} objects, reading {numbytes} bytes")            if (args.only_textures.lower() == "false"):              for i in range(numobjects):                  data.tlist.append(readTlist(version,f))            else:              try:                print(f"    Only texture requested: skipping {l_name[listtype]}  ({numbytes} bytes)")                skipBytes(f, numbytes)              except Exception as e:                print(f"**** Error while skipping LIST: '{e}'")                traceback.print_exc()        elif listtype == L_ILIST:            if (args.verbose >=1) : print(f"  L_ILIST (l_name[listtype]),  {numobjects} objects, reading {numbytes} bytes")            if (args.only_textures.lower() == "false"):              for i in range(numobjects):                  data.ilist.append(readIlist(version,f))            else:              try:                print(f"    Only texture requested: skipping {l_name[listtype]}  ({numbytes} bytes)")                skipBytes(f, numbytes)              except Exception as e:                print(f"**** Error while skipping LIST: '{e}'")                traceback.print_exc()        else:            if (args.verbose >=1) : print(f'  {l_name[listtype]}  unsupported - skipping {numbytes} bytes')            f.read(numbytes)    except Exception as error:        breakf.close()if (args.verbose >=1):   print("\n------------- PFB file parsing completed -------------------\n")######################################if (args.only_textures != False):    passelse:  if (args.verbose >=2):   print("\n==============================")  if (args.verbose >=2):   print("======= NODES STRUCTURE =======\n")  roots = build_node_tree(data.node)  for r in roots:      if (args.verbose >=2):    print_node_tree(data.node, r)  if (args.verbose >=2):   print("\n==============================")  if (args.verbose >=2):   print("======= LODS STRUCTURE =======\n")  LODS = build_LODS(data.node)  lodIndex = 0  for l in LODS:      if (args.verbose >=2):   print(f"LOD {lodIndex} (node {l['node_index']})")      if (args.verbose >=2):   print(f"  ranges      : {l['ranges']}")      if (args.verbose >=2):   print(f"  transitions : {l['transitions']}")      if (args.verbose >=2):   print(f"  children    : {l['children']}")      if (args.verbose >=2):   print(f"  geosets     :")      for i, gs in enumerate(l["geosets"]):          pass          # print(f"    range {i} -> {gs}")      lodIndex += 1################### Output files OBJ+MTL creation ###############import os# -------- INPUT INFO --------inputPath = os.path.dirname(args.input)inputName = os.path.basename(args.input)inputNameWithoutExtension = os.path.splitext(inputName)[0]# -------- CASE 1: output OBJ esplicito --------if args.output:    obj_filename = os.path.abspath(args.output)    finalFullOutputFolder = os.path.dirname(obj_filename)    objName = os.path.basename(obj_filename)    mtlName = os.path.splitext(objName)[0] + ".mtl"    mtl_filename = os.path.join(finalFullOutputFolder, mtlName)    print(f"{objName}, {mtlName}, {mtl_filename}")    finalFullOutputFolderTextures = os.path.join(        finalFullOutputFolder,        args.textures_folder if args.textures_folder else "textures"    )# -------- CASE 2: solo input, usa default --------else:    obj_filename = os.path.abspath(args.input)    objName = os.path.basename(obj_filename)    mtlName = os.path.splitext(objName)[0] + ".mtl"    # base folder (opzionale)    base_folder = "" # args.base_folder if args.base_folder else inputPath    # cartella modelli (opzionale)    models_folder = args.output_folder if args.output_folder else "models"    # cartella specifica del modello    modelNameFolder = inputNameWithoutExtension    finalFullOutputFolder = os.path.join(        base_folder,        models_folder,        modelNameFolder    )    # textures accanto a obj/mtl    finalFullOutputFolderTextures = os.path.join(        finalFullOutputFolder,        args.textures_folder if args.textures_folder else "textures"    )    obj_filename = os.path.join(        finalFullOutputFolder,        f"{inputNameWithoutExtension}_LOD{args.LOD}.obj"    )    mtl_filename = os.path.join(        finalFullOutputFolder,        f"{inputNameWithoutExtension}.mtl"    )# -------- CREATE FOLDERS --------os.makedirs(finalFullOutputFolderTextures, exist_ok=True)if args.verbose >= 1:    print(f"[OBJ] Output folder     : {finalFullOutputFolder}")    print(f"[OBJ] Textures folder   : {finalFullOutputFolderTextures}")    print(f"[OBJ] OBJ file          : {obj_filename}")    print(f"[OBJ] MTL file          : {mtl_filename}")if (args.verbose >=1):  print("")if (args.verbose >=1):  print("[OBJ] ============== OUTPUT FILES (OBJ + MTL) CREATION #############")try:  if (args.verbose >=1):  print(f"[OBJ] Creating MTL file")  mtl_file = open( mtl_filename,'w')  if (args.verbose >=2):  print(f"Result: {mtl_file}\n")except Exception as e:     print(f"[OBJ]    ======== OBJ file creation EXCEPTION ==========")     traceback.print_exc()    ################# Extract textures list ##########if (args.only_textures.lower() == "true"):    try:        i = 0        for texture in data.tex:            mtl_file.write(f"newmtl gstate{i}\n")            textureFilename = NASAtextureSearch(texture.filename.lower(), finalFullOutputFolder)            texRefInObj = os.path.join(args.textures_folder,textureFilename)            mtl_file.write(f"map_Kd {texRefInObj}\n")            mtl_file.write("\n")            i += 1        print_not_found_textures()        if (args.verbose >=1):  print("[OBJtex] MTL completed")    except Exception as e:        print("[OBJtex] ======== ONLY MTL file creation EXCEPTION ==========")        traceback.print_exc()else:#   for gstate in data.gstate:    try:        i = 0        for gstate in data.gstate:            mtl_file.write(f"newmtl gstate{i}\n")            if (args.verbose >=1):      print(f"\n[OBJFULL] Gstate {i} texture pointer: {gstate.texture}")            if gstate.texture > -1:                tex = data.tex[gstate.texture] # gstate.texture is a pointer to the texture in L_TEX list, which is stored in data.tex            if gstate.frontmtl > -1:                mtl = data.mtl[gstate.frontmtl]                mtl_file.write(f"Ka {mtl.ambient[0]} {mtl.ambient[1]} {mtl.ambient[2]}\n")                mtl_file.write(f"Kd {mtl.diffuse[0]} {mtl.diffuse[1]} {mtl.diffuse[2]}\n")                mtl_file.write(f"Ks {mtl.specular[0]} {mtl.specular[1]} {mtl.specular[2]}\n")                mtl_file.write(f"Ns {mtl.shininess}\n")            if gstate.texture > -1:                tex = data.tex[gstate.texture]                if (args.texture == "NASA"):                  finalTextureName = NASAtextureSearch(tex.filename.lower(), finalFullOutputFolder)                else:                  finalTextureName = tex.filename.lower().replace(args.texture_source_extension, args.texture_destination_extension)                  if (args.verbose >=1):   print(f"[OBJFULL-nonNASA] {finalTextureName}\n")            texRefInObj = os.path.join(args.textures_folder,finalTextureName)            mtl_file.write(f"map_Kd {texRefInObj}\n")            mtl_file.write("\n")            i += 1        if (args.verbose >=1):  print("\n[OBJFULL] MTL completed\n")        mtl_file.close()    except Exception as e:        print("[OBJFULL] ======== MTL file creation EXCEPTION ==========")        traceback.print_exc()if (args.verbose >=1):  print("[OBJ] Creating OBJ file contents")try:  if (args.verbose >=2):   print("[OBJ]     Extracting geosets for selected LOD level...")  LODS = build_LODS(data.node)  if (args.verbose >=1):   print(f"[OBJ]     {len(LODS)} LODS found. ")  selected_geosets = set()  if len(LODS) > 0:    lod_level = args.LOD    if (args.verbose >=2):    print(f"[OBJ]     Finding designated geosets by LOD level. {lod_level}")    selected_geosets = select_geosets_for_lod(LODS, lod_level)    if (args.verbose >=2):    print(f"{len(selected_geosets)} geosets with LODs:{selected_geosets}")  else:    if (args.verbose >=2):     print("[OBJ]     No LODs in file: collecting all geosets.")# DEBUG: VECCHIA VERSIONE per altri PFB, controllare e rimettere#       for i, n in enumerate(data.node):#           # print(f"[OBJ]     Examining node n.{i}")#           allGeosets = []#           for r_index, child in enumerate(n.children):#               geosets = collect_geosets_under_node(nodes, child)#               # print(f"[OBJ]       Collecting geosets {r_index}")#               allGeosets.append(geosets)#               selected_geosets = allGeosets  # print(f"{len(selected_geosets)} geosets without LODs:{selected_geosets}")  pairs = []  for geoset in selected_geosets:      pairs.append(f"G{geoset}")  # print(f"[OBJ]     Geosets to convert: {', '.join(pairs)}")except Exception as e:    print(f"[OBJ]    ======== OBJ EXCEPTION ==========")    traceback.print_exc()if (args.only_textures.lower() == "true") :    print("\n\n[OBJ] ========== Only textures requested by user, skipping OBJ creation, program ended. ========")    exit(0)if (args.verbose >=1):  print(f"[OBJ]     Creating OBJ file")try:    obj_file = open(obj_filename,'w')except Exception as e:    print(f"[OBJ]    ======== OBJ file creation error ==========")    traceback.print_exc()if (args.verbose >=1):  print(f"[OBJ]     Writing MTL header to OBJ file {obj_filename}")try:    obj_file.write(f'mtllib {mtlName}\n')except Exception as e:    print(f"[OBJ]    ======== OBJ file writing error ==========")    traceback.print_exc()try:  numverts = 0  numnorms = 0  if (args.verbose >=1): print (f"[OBJ]     Looking for geosets in nodes...")  nodeCounter = -1  if len(LODS) > 0:    geoset_ids = set(int(identifier.split('/')[0]) for identifier in selected_geosets if identifier.split('/')[0].isdigit())          geosetsCount = -1  for n in data.node:      nodeCounter = nodeCounter + 1      if (args.verbose >=2): print(f"[OBJ]      Node n. {nodeCounter}")      if n.type == N_GEODE:          if (args.verbose >=2):print(f"[OBJ]       Geode detected, processing geosets")          for g in n.gsets: # Process all geosets in PFB file              geosetsCount = geosetsCount + 1              if len(LODS) > 0:  # If file is structured in LODs, process only geosets associated to specified LOD level                if g not in geoset_ids:                    if (args.verbose >=2): print(f"[OBJ]       Geoset n. {geosetsCount}: SKIPPED (not in selected_geosets: {sorted(geoset_ids)})")                    continue  # Skip this geoset              if (args.verbose >=2): print(f"[OBJ]       Geoset n. {geosetsCount}: PROCESSING")              coords = []              norms = []              texc = []              lens = []              gset = data.gset[g]              # print(f"[OBJ]        Geoset is made of {gset.pcount} primitives of type {gset.ptype} ({gspt_table_strings[gset.ptype]})")              obj_file.write(f'#gset type {gset.ptype}   numprims {gset.pcount}   gstate {gset.gstate}\n')              if gset.llist != -1:                 if (args.verbose >=2): print("[OBJ]        Extracting lengths")                 lens = data.llist[gset.llist]                 obj_file.write(f'#  lenlist: {lens}\n')              if gset.vlist[1] != -1:                 if (args.verbose >=2): print("[OBJ]        Extracting vertices")                 coords = data.vlist[gset.vlist[1]]              else:                 if (args.verbose >=2): print("[OBJ]        (no data, skipping geoset)")                 continue    # i.e. if there's no list of vertices, just skip this geoset              if gset.vlist[2] != -1:                  if (args.verbose >=2): print("[OBJ]          Extracting vertex indices")                  indices = data.ilist[gset.vlist[2]]                  coords = [coords[i] for i in indices]              vstart = numverts              for v in coords:                  obj_file.write(f'v {v[0]} {v[1]} {v[2]}\n')                  numverts += 1  #NOTE: this code assumes that normals & texcoords are per-vertex.  Support for PFGS_OVERALL and PFGS_PER_PRIM will need to be added.              normal_mode = gsb_table[gset.nlist[0]]              if normal_mode != PFGS_PER_VERTEX:                  obj_file.write('          ####WARNING: unsupported normal mode !!!!\n')              nstart = numnorms # <--- SALVIAMO L'OFFSET DI PARTENZA              if gset.nlist[1] != -1:                  if (args.verbose >=2): print("[OBJ]        Extracting normals")                  norms = data.nlist[gset.nlist[1]]                  if gset.nlist[2] != -1:                      if (args.verbose >=2): print("[OBJ]          Extracting normals indices")                      indices = data.ilist[gset.nlist[2]]                      norms = [norms[i] for i in indices]                  for n in norms:                      obj_file.write(f'vn {n[0]} {n[1]} {n[2]}\n')                      numnorms += 1 # <--- INCREMENTIAMO IL CONTATORE              else:                  # Se non ci sono normali in questo geoset, nstart resta quello corrente                  pass                  #               if gset.nlist[1] != -1:#                   # print("[OBJ]        Extracting normals")#                   norms = data.nlist[gset.nlist[1]]#                   if gset.nlist[2] != -1:#                       # print("[OBJ]        Extracting indices")#                       indices = data.ilist[gset.nlist[2]]#                       norms = [norms[i] for i in indices]#                   # print("[OBJ]        Writing to file")#                   for n in norms:#                       obj_file.write(f'vn {n[0]} {n[1]} {n[2]}\n')              texc_mode = gsb_table[gset.tlist[0]]              if (texc_mode != PFGS_PER_VERTEX) and (texc_mode != PFGS_OFF):                  obj_file.write('          #WARNING: unsupported texture coordinate mode !!!!\n')              if gset.tlist[1] != -1:                  if (args.verbose >=2): print("[OBJ]        Extracting colors... ")                  texc = data.tlist[gset.tlist[1]]                  if gset.tlist[2] != -1:                      if (args.verbose >=2):  print("[OBJ]        Extracting indices...")                      indices = data.ilist[gset.tlist[2]]                      texc = [texc[i] for i in indices]                  # print("[OBJ]        Writing to file")                  for t in texc:                      obj_file.write(f'vt {t[0]} {t[1]}\n')  # --- VALIDAZIONE DATI ---              is_flat_strip = (gspt_table_strings[gset.ptype] == "PFGS_FLAT_TRISTRIPS")              is_standard_strip = (gspt_table_strings[gset.ptype] == "PFGS_TRISTRIPS")              # Controllo coerenza lunghezze (modificato per supportare FLAT)              if not is_flat_strip:                  if len(coords) != len(norms) and normal_mode == PFGS_PER_VERTEX:                      obj_file.write('#ERROR: coords <> normals - mismatch for standard strip !!!!\n')                      # print('#ERROR: coords <> normals - mismatch !!!!')              else:                  # Per FLAT strips: Numero Normali = Somma(Lunghezze - 2)                  expected_normals = sum(l - 2 for l in lens)                  if len(norms) != expected_normals and len(norms) > 0:                       msg = f'#WARNING: Flat Strip mismatch. Verts: {len(coords)}, Norms: {len(norms)}, Expected Norms: {expected_normals}'                       obj_file.write(msg + '\n')                       # print(msg)              if len(coords) != len(texc) and texc_mode != PFGS_OFF:                  obj_file.write('#ERROR: coords <> texc - only per-vertex is supported !!!!\n')              # --- GESTIONE MATERIALI ---              if gset.gstate[0] != -1:                  obj_file.write(f'usemtl gstate{gset.gstate[0]}\n')              # --- DISEGNO STRISCE (STANDARD E FLAT) ---              if is_standard_strip or is_flat_strip:                  # print(f"[OBJ]      Primitive of type {gspt_table_strings[gset.ptype]} processing...")                  # Offset locale all'interno degli array di questo singolo GeoSet                  local_v_idx = 0                   local_n_idx = 0                                     # vstart e nstart sono gli offset GLOBALI nel file OBJ calcolati prima                  for striplen in lens:                      ccw = ccwRef #True #  debug                      # Un triangolo in una strip Ã¨ definito da i, i+1, i+2                      # Il loop itera per il numero di triangoli (lunghezza - 2)                      for tri in range(striplen - 2):                                                    # 1. Calcolo Indice Vertice Globale                          # Il triangolo inizia al vertice locale: local_v_idx + tri                          # Aggiungiamo vstart per ottenere l'indice globale OBJ                          current_global_v = vstart + local_v_idx + tri                          # 2. Calcolo Indice Normale Globale                          if is_flat_strip:                              # In FLAT, le normali sono compattate (niente normali per i primi 2 vertici).                              # La normale del triangolo 'tri' (0, 1, 2...) Ã¨ sequenziale nell'array delle normali.                              # Quindi basta avanzare linearmente col triangolo.                              current_global_n = nstart + local_n_idx + tri                          else:                              # In STANDARD, le normali sono 1:1 con i vertici.                              # Usiamo lo stesso offset dei vertici.                              current_global_n = nstart + local_v_idx + tri                          # Chiamata alla funzione (che deve avere la firma aggiornata con is_flat)                          print_tristrip_triangle(                              firstindex_v=current_global_v,                              firstindex_n=current_global_n,                              normal_mode=normal_mode,                               texc_mode=texc_mode,                              ccw=ccw,                              is_flat=is_flat_strip                          )                                                    ccw = not ccw # Inverte il winding per il prossimo triangolo                                            # Fine della strip: avanziamo gli indici locali                      local_v_idx += striplen                                            if is_flat_strip:                          # In una flat strip di N vertici, consumiamo N-2 normali                          local_n_idx += (striplen - 2)                      else:                          # In una standard strip, consumiamo N normali                          local_n_idx += striplen              else:                print(f"=== WARNING! Primitive {gspt_table_strings[gset.ptype]} NOT supported yet.")#               if (len(coords) != len(norms)):#                   obj_file.write('#ERROR: coords <> normals - only per-vertex is supported !!!!\n')#                   # print('#ERROR: coords <> normals - only per-vertex is supported !!!!\n')#               if (len(coords) != len(texc)):#                   obj_file.write('#ERROR: coords <> texc - only per-vertex is supported !!!!\n')#                   # print('#ERROR: coords <> texc - only per-vertex is supported !!!!\n')# #   #NOTE: should look up how pfGSetGStateIndex() works (if gstate[1] is not -1); probably none of our models use that feature, however#               if gset.gstate[0] != -1:#                   obj_file.write(f'usemtl gstate{gset.gstate[0]}\n')#               if (gspt_table_strings[gset.ptype] == "PFGS_TRISTRIPS") | (gspt_table_strings[gset.ptype] == "PFGS_FLAT_TRISTRIPS"):#                   if (gspt_table_strings[gset.ptype] == "PFGS_FLAT_TRISTRIPS"):#                       # print(f"[OBJ] Warning: triangle strips is FLAT, texture not correctly supported/implemented")#                   # print(f"[OBJ]      Primitive of type {gspt_table_strings[gset.ptype]} is supported! Creating faces...")#                   stripstart = vstart#                   for striplen in lens:#                       vertindex = stripstart#                       ccw = True#                       for tri in range(striplen-2):#                           # print("[OBJ]      Writing faces to file")#                           # print_tristrip_triangle(vertindex, normal_mode, texc_mode, ccw)#                           vertindex += 1#                           ccw = not ccw#                       stripstart += striplen#   #             elif gspt_table_strings[gset.ptype] == "PFGS_FLAT_TRISTRIPS": #######################################################################   #                 # print("[OBJ]      :-( Primitive {gset.ptype} to be implemented...")#   #                 #write_flat_tristrips_to_obj(lens, coords)#               else:#                   # print("=== WARNING! Only PFGS_TRISTRIPS supported, no mesh drawn or this geoset, only pointcloud will be shown")      elif n.type == N_LOD:          # print(f"[OBJ]       LOD detected")          # Possiamo aggiungere informazioni sul LOD qui          if hasattr(n, 'ranges'):              # print(f"[OBJ]        Ranges: {n.ranges}")              if hasattr(n, 'children'):                  pass                  # print(f"[OBJ]        Children nodes: {n.children}")      else:          node_name = node_type_dict.get(n.type, f"UNKNOWN_NODE_{n.type}")          # print(f"[OBJ]      ------- (non-Geode, skipping node of type {n.type} ({node_name}))")except Exception as e:    print(f"[OBJ]   ======== LOD SELECTION EXCEPTION: file writing error ==========")    traceback.print_exc()print("[OBJ]     Nodes finished, OBJ file completed.")if (args.verbose >=2):   print("\n============== page for textures =============")#if (args.verbose >=2):   print(f"{html}")obj_file.close()